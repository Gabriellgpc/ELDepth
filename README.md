# ELDepth
ELDepth: Extreme Low-Power Monocular Depth Estimation for mobile devices

## Models evaluated
- [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/abs/1505.04597)
- [Squeeze U-Net: A Memory and Energy Efficient Image Segmentation Network](https://openaccess.thecvf.com/content_CVPRW_2020/papers/w22/Beheshti_Squeeze_U-Net_A_Memory_and_Energy_Efficient_Image_Segmentation_Network_CVPRW_2020_paper.pdf)
- [LiteDepth: Digging into Fast and AccurateDepth Estimation on Mobile Devices](https://arxiv.org/abs/2209.00961)

## Datasets
- [DIODE: A Dense Indoor and Outdoor DEpth Dataset](https://diode-dataset.org/)
- [NYU Depth Dataset V2](https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html)
- [The KITTI Vision Benchmark Suite](https://www.cvlibs.net/datasets/kitti/eval_depth.php?benchmark=depth_prediction)


## Future work
- Model destilltion (base code)[https://keras.io/examples/keras_recipes/better_knowledge_distillation/]
- Dynamic quantization
- SSL