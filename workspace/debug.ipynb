{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "# from src.data.dataloader import DataGenerator\n",
    "from src.data.augmentation import random_crop, random_rotate, random_flip_left_right\n",
    "from src.data.dataloader import build_tf_dataloader, parser_DIODE_dataset\n",
    "from src.helpers import setup_gpu\n",
    "from src.viz.plot_images import visualize_depth_map\n",
    "setup_gpu(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = pd.read_csv('/workspace/tmp/DIODO_val.csv')\n",
    "validation_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = [ parser_DIODE_dataset, random_crop, random_rotate]\n",
    "dataloader = build_tf_dataloader( validation_df['image'].values,\n",
    "                                  validation_df['depth'].values,\n",
    "                                  validation_df['mask'].values,\n",
    "                                  batch_size=16,\n",
    "                                  transforms=transform,\n",
    "                                  train=True,\n",
    "                                  )\n",
    "\n",
    "sample = next(iter( dataloader ))\n",
    "_ = visualize_depth_map(sample)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = np.random.randint(0, len(validation_df))\n",
    "# mask = np.load(validation_df['mask'].values[idx])\n",
    "# mask = np.expand_dims(mask, axis=-1)\n",
    "\n",
    "# depth = np.load(validation_df.depth.values[idx])\n",
    "# depth = np.clip(depth, 0.6, 350) / 350.0\n",
    "\n",
    "# print(depth.shape)\n",
    "# print(depth.min(), depth.mean(), depth.max())\n",
    "\n",
    "# # max_depth = min(300, depths.max())\n",
    "# # depths = np.clip(depths, 0.1, max_depth)\n",
    "# # depths = np.log(depths)\n",
    "# # depths = np.ma.masked_where(~(masks > 0), depths)\n",
    "# # depths = np.clip(depths, 0.1, np.log(max_depth))\n",
    "\n",
    "# viz_depth = np.log(depth)\n",
    "# viz_depth = np.ma.masked_where( ~(mask>0), viz_depth )\n",
    "\n",
    "\n",
    "# cmap = plt.cm.get_cmap(\"jet\").copy()\n",
    "# cmap.set_bad(color=\"black\")\n",
    "# plt.imshow( viz_depth , cmap=cmap)\n",
    "# plt.show()\n",
    "\n",
    "# # depth in m\n",
    "# # –  Return Density: 99.6% (indoor) / 66.9% (outdoor)\n",
    "# # –  Depth Precision: ±1 mm\n",
    "# # –  Angular Resolution: 0.009°\n",
    "# # –  Max Range: 350 m\n",
    "# # –  Min Range: 0.6 m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(image_path):\n",
    "    content = tf.io.read_file(image_path)\n",
    "    ext = tf.strings.split(image_path, '.')[-1]\n",
    "    ext = tf.strings.lower(ext)\n",
    "\n",
    "    bmp_decode  = lambda: tf.image.decode_bmp(content, channels=3)\n",
    "    png_decode  = lambda: tf.image.decode_png(content, channels=3)\n",
    "    jpeg_decode = lambda: tf.image.decode_jpeg(content, channels=3, try_recover_truncated=True)\n",
    "\n",
    "    image = tf.case([ (ext == tf.constant('bmp'), bmp_decode),\n",
    "                    (ext == tf.constant('png'), png_decode),\n",
    "                    (ext == tf.constant('jpg'), jpeg_decode),\n",
    "                    (ext == tf.constant('jpeg'), jpeg_decode),\n",
    "                  ], default=bmp_decode)\n",
    "    image = tf.image.convert_image_dtype(image, dtype='float32') #will be in [0, 1]\n",
    "    return image\n",
    "\n",
    "def load_images(filenameA, filenameB):\n",
    "    return read_image(filenameA), read_image(filenameB)\n",
    "\n",
    "def load_numpy(filename):\n",
    "    filename = filename.numpy().decode('utf-8')\n",
    "    np_loaded = np.load(filename)\n",
    "    return np_loaded\n",
    "\n",
    "def load_image_depth_mask(input_path, depth_path, mask_path):\n",
    "    # read as RGB and convert to [0, 1], float32\n",
    "    input_image = read_image(input_path)\n",
    "    h, w = input_image.shape[:2]\n",
    "    # load depth map\n",
    "    [depth,] = tf.py_function(load_numpy, [depth_path], [tf.float32])\n",
    "    depth.set_shape( [h,w,1] )\n",
    "    # load valid mask\n",
    "    [mask,] = tf.py_function(load_numpy, [mask_path], [tf.float32])\n",
    "    # put mask in [H,W,1] format\n",
    "    mask = tf.expand_dims(mask, axis=-1)\n",
    "    mask.set_shape( [h,w,1] )\n",
    "    return input_image, depth, mask\n",
    "\n",
    "def basic_image_depth_mask_preproc(input_image, depth, mask, min_max_depth=[0.1, 350.0]):\n",
    "\n",
    "    # depth = tf.clip_by_value(depth, min_max_depth[0], min_max_depth[1])\n",
    "    # depth = tf.math.log(depth)\n",
    "    # depth = depth * (1.0 - mask)\n",
    "    # depth = tf.clip_by_value(depth, min_max_depth[0], tf.math.log(min_max_depth[1]))\n",
    "\n",
    "    return input_image, depth, mask\n",
    "\n",
    "def build_tf_dataloader(input_paths, depth_paths, mask_paths, batch_size=32, transforms=[], train=True):\n",
    "    data = tf.data.Dataset.from_tensor_slices( (input_paths, depth_paths, mask_paths) )\n",
    "    if train:\n",
    "        data = data.shuffle(1024)\n",
    "\n",
    "    data = data.map(load_image_depth_mask, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    # data = data.map(basic_image_depth_mask_preproc, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    for transform_f in transforms:\n",
    "        data = data.map(transform_f, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    # data = data.batch(batch_size).cache().prefetch(tf.data.AUTOTUNE)\n",
    "    data = data.batch(batch_size)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ib, db, mb = load_image_depth_mask(validation_df['image'].values[0],\n",
    "                                   validation_df['depth'].values[0],\n",
    "                                   validation_df['mask'].values[0],\n",
    "                                   )\n",
    "\n",
    "ib, db, mb = basic_image_depth_mask_preproc(ib, db, mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_tf_dataloader( validation_df['image'].values,\n",
    "                               validation_df['depth'].values,\n",
    "                               validation_df['mask'].values,\n",
    "                               batch_size=25,\n",
    "                               transforms=[],\n",
    "                               train=True,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, depths, masks = next(iter(dataset))\n",
    "\n",
    "images = images.numpy()\n",
    "depths = depths.numpy()\n",
    "masks = masks.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths.min(), depths.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths.min(), depths.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth = min(300, np.percentile(depths, 99))\n",
    "max_depth = min(300, depths.max())\n",
    "depths = np.clip(depths, 0.1, 350)\n",
    "depths = np.log(depths)\n",
    "depths = np.ma.masked_where(~(masks > 0), depths)\n",
    "depths = np.clip(depths, 0.1, np.log(max_depth))\n",
    "\n",
    "cmap = plt.cm.get_cmap(\"jet\").copy()\n",
    "cmap.set_bad(color=\"black\")\n",
    "\n",
    "fig, ax = plt.subplots(6, 2, figsize=(50, 50))\n",
    "for i in range(6):\n",
    "    ax[i, 0].imshow((images[i].squeeze()))\n",
    "    ax[i, 1].imshow((depths[i].squeeze()), cmap=cmap)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
